
<!DOCTYPE html>
<html>
    <head>
        
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Jingru Guo">

<title>Parameter optimization in neural networks</title>




<!-- Fonts -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
<link href="https://fonts.googleapis.com/css?family=Assistant:300,400,600,700" rel="stylesheet">
<!-- Load jquery -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<!--Favicon-->
<link rel="shortcut icon" type="image/png" href="/assets/images/layout/favicon.png"/>





<!-- Article CSS -->
<link rel="stylesheet" href="/assets/css/article.css">

<!-- Load D3 -->
<script src="https://d3js.org/d3.v5.min.js"></script>

<!-- Load Tensorflow -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.3/dist/tf.min.js"></script>

<!-- Load Katex -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body, {delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false}
    ]});">
</script>

<!-- Load GreenSock and Snap SVG -->
<script src="/assets/js/TweenMax.min.js"></script>
<script src="/assets/js/Draggable.min.js"></script>
<script src="/assets/js/DrawSVGPlugin.min.js"></script>
<script src="/assets/js/MorphSVGPlugin.min.js"></script>
<script src="/assets/js/ThrowPropsPlugin.min.js"></script>
<script src="/assets/js/snap.svg-min.js"></script>

<!-- Load JS -->
<script src= "/assets/js/cppn.js"></script>
<script src= "/assets/js/d3.tip.js"></script>
<script src= "/assets/js/tool.js"></script>
<script src="https://d3js.org/d3-contour.v1.min.js"></script>
<script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3-legend/2.25.6/d3-legend.min.js"></script>


<!-- Load Highlight -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/monokai-sublime.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


    
     

    </head>


  <body>
    <header class="header"> 
    <div class="header-wrapper">
        <ul>
            <li>
                <a href="https://www.deeplearning.ai/">
                    <img src="/assets/images/layout/deeplearning.png">
                </a>
            </li>
            <li> <a href="/" class="backToBlog">AI Notes</a></li>
           
              
                <li class="header-nav-article"><a href="/initialization">Initialization</a></li>
              
           
              
                <li class="header-nav-article"><a href="/optimization">Optimization</a></li>
              
           
              
                <li class="header-nav-article"><a href="/regularization">Regularization</a></li>
              
           
        </ul>
    </div>
</header> 

     <div class="main">
        <div class="container article-banner" >
        	
            <div class="article-banner-content" id="vis-background">
    <div id="cppn-overlay"></div>  
</div>
<div>
    <a class="cppn-control-toggle">
      <div class="cppn-control">
        <i class="fas fa-sliders-h"></i>
      </div>
    </a>
    <div class="cppn-control" style="display: none">
      <a class="cppn-control-toggle fa fa-times"></a>
      <p>Network Depth:</p>
      <label class="radio-container">
          Shallow
          <input type="radio" name="depth" value="3" checked/>
          <span class="checkmark"></span>
      </label>
      <label class="radio-container">
          Deep
          <input type="radio" name="depth" value="4" />
          <span class="checkmark"></span>
      </label>
      <p>Layer Complexity:</p>
      <label class="radio-container">
          Simple
          <input type="radio" name="complexity" value="20" checked/>
          <span class="checkmark"></span>
      </label>
      <label class="radio-container">
          Complex
          <input type="radio" name="complexity" value="25" />
          <span class="checkmark"></span>
      </label>
      <p>Nonlinearity:</p>
      <select id="activation" class="select-containter">
          <option value="sin" selected>Sine</option>
          <option value="cos">Cosine</option>
          <option value="tanh">Tanh</option>
          <option value="linear">Linear</option>
          <option value="step">Step</option>
          <option value="relu">Relu</option>
          <option value="leakyRelu">Leaky Relu</option>
      </select>
    </div>
</div>
<script type="text/javascript">

    $(".cppn-control-toggle").click(function() {
      $(".cppn-control").toggle();
    })

    var c1 = "120 184 66".split(" "),
        c2 = "45 155 106".split(" ");
        c3 = "0 125 117".split(" ");

    var cppn = cppnSetup([c1, c2, c3]),
        layers = 3,
        unit = 20
        activation = "sin";

    $("input[name='depth']").on("change", function () {
      layers = parseInt($(this).val());
      cppn.update(architecture(layers, unit), activation)
    });

    $("input[name='complexity']").on("change", function () {
      unit = parseInt($(this).val());
      cppn.update(architecture(layers, unit), activation)
    });

    $("#activation").on("change", function() {
      activation = $(this).val();
      cppn.update(architecture(layers, unit), activation)
    });


    function architecture(layers, units) {
      var arr = [5];
      for (var i = 0; i < layers; i++) {
        arr.push(units);
      }
      arr.push(3);
      return arr;
    }
</script>
            
            <div class="banner-title" >
                <h1>Parameter optimization in neural networks</h1>
                <p>Training a machine learning model is a matter of closing the gap between the model's predictions and the observed training data labels. But optimizing the model parameters isn't so straightforward. Through interactive visualizations, we'll help you develop your intuition for setting up and solving this optimization problem.</p>
            </div>
            
        </div>


        <div class="tableOfContent">
        		<p>TABLE OF CONTENTS</p>
	        	<ul id="toc">
	        		
	        			<li><span> I </span> <a href="#I">Setting up the optimization problem</a></li>
	                
	        			<li><span> II </span> <a href="#II">Running the optimization process</a></li>
	                
	        	</ul>

        </div>

        <section class="article-content">
        		<p>In machine learning, you start by defining a task and a model. The model consists of an architecture and parameters. For a given architecture, the values of the parameters determine how accurately the model performs the task.
But how do you find good values? By defining a loss function that evaluates how well the model performs. The goal is to minimize the loss and thereby to find parameter values that match predictions with reality. This is the essence of training.</p>

<h1 id="I">I   Setting up the optimization problem</h1>

<p>The <span class="sidenote">loss function</span> will be different in different tasks depending on the output desired. How you define it has a major influence on how the model will train and perform. Let’s consider two examples:</p>

<h3 id="example-1-house-price-prediction">Example 1: House price prediction</h3>

<p>Say your task is to predict the price of houses $y \in \mathbb{R}$ based on features such as floor area, number of bedrooms, and ceiling height. The squared loss function can be summarized by the sentence:</p>

<blockquote>
  <p>Given a set of house features, the square of the difference between your prediction and the actual price should be as small as possible.</p>
</blockquote>

<p>This loss function is</p>

<div class="kdmath">$$
\mathcal{L} = ||y-\hat{y}||_2^2
$$</div>

<p>where $\hat{y}$ is your predicted price and $y$ is the actual price, also known as ground truth.</p>

<h3 id="example-2-object-localization">Example 2: Object localization</h3>

<p>Let’s consider a more complex example. Say your task is to localize the car in a set of images that contain one. The loss function should frame the following sentence in mathematical terms:</p>

<blockquote>
  <p>Given an image containing one car, predict a bounding box (bbox) that surrounds the vehicle. The predicted box should match the size and position of the actual car as closely as possible.</p>
</blockquote>

<p>In mathematical terms, a possible loss function $\mathcal{L}$ (Redmon et al., 2016) is:</p>

<div class="kdmath">$$
\mathcal{L} = \underbrace{(x - \hat{x})^2 + (y - \hat{y})^2}_{\text{BBox Center}} + \underbrace{(w - \hat{w})^2 + (h - \hat{h})^2}_{\text{BBox Width/Height}}
$$</div>

<p>This loss function depends on:</p>

<ul>
  <li>The model’s prediction which, in turn, depends on the parameter values (weights) as well as the input (in this case, images).</li>
  <li>The ground truth corresponding to the input (labels; in this case, bounding boxes).</li>
</ul>

<h3 id="cost-function">Cost function</h3>

<p>Note that the loss $\mathcal{L}$ takes as input a single example, so minimizing it doesn’t guarantee better model parameters for other examples.</p>

<p>It is common to minimize the average of the loss computed over the entire training data set; $\mathcal{J} = \frac{1}{m} \sum_{i=1}^{m} \mathcal{L}^{(i)}$. We call this function the cost. $m$ is the size of the training data set and $\mathcal{L}^{(i)}$ is the loss of a single training example $x^{(i)}$ labelled $y^{(i)}$.</p>

<h3 id="visualizing-the-cost-function">Visualizing the cost function</h3>

<p>For a given set of examples along with the corresponding ground truth labels, the cost function has a landscape that varies as a function of the parameters of the network.</p>

<p>It is difficult to visualize this landscape if there are more than two parameters. However, the landscape does exist, and our goal is to find the point where the cost function’s value is (approximately) minimal.</p>

<p>Updating the parameter values will move the value either closer to or farther from the target minimum point.</p>

<h3 id="the-model-versus-the-cost-function">The model versus the cost function</h3>

<p>It is important to distinguish between the function $f$ that will perform the task (the model) and the function $\mathcal{J}$ you are optimizing (the cost function).</p>

<ul>
  <li>The model inputs an unlabeled example (such as a picture) and outputs a label (such as a bbox for a car). It is defined by an architecture and a set of parameters, and approximates a <span class="sidenote">real function</span> that performs the task. Optimized parameter values will enable the model to perform the task with relative accuracy.</li>
  <li>The cost function inputs a set of parameters and outputs a cost, measuring how well that set of parameters performs the task (on the training set).</li>
</ul>

<h3 id="optimizing-the-cost-function">Optimizing the cost function</h3>

<p>Initially, good parameter values are unknown. However, you have a formula for the cost function. Minimize the cost function, and theoretically you will find good parameter values. The way to do this is to feed a training data set into the model and adjust the parameters iteratively to make the cost function as small as possible.</p>

<p>In summary, the way you define the cost function will dictate the performance of your model on the task at hand. The diagram below illustrates the process of finding a model that performs well.</p>

<p><img src="../assets/images/article/optimization/optimization_chart.png" alt="optimization_chart" title="optimization_chart" /></p>

<h1 id="II">II   Running the optimization process</h1>

<p>In this section, we assume that you have chosen a task, a data set, and a cost function. You will minimize the cost to find good parameter values.</p>

<h3 id="using-gradient-descent">Using gradient descent</h3>

<p>To find parameter values that achieve a function’s minimum, you can either try to derive a <span class="sidenote">closed form</span> solution algebraically or approximate it using an iterative method. In machine learning, iterative methods such as gradient descent are often the only option because cost functions are dependent on a large number of variables, and there is almost never any practical way to find a closed form solution for the minimum.</p>

<p>For gradient descent, you must first initialize the parameter values so that you have a starting point for optimization. Then, you adjust the parameter values iteratively to reduce the value of the cost function. At every iteration, parameter values are adjusted according to the opposite direction of the gradient of the cost; that is, in the direction that reduces the cost.</p>

<p>The mathematical procedure to remember is:</p>

<p>$\quad \text{for x in dataset:}$</p>

<p>$\quad \quad \quad \hat{y} = model_W(x) \quad \quad \text{(predict)}$</p>

<p>$ \quad \quad \quad W = W - \alpha \frac{\partial \mathcal{J}(y, \hat{y})}{\partial W} \quad \quad \text{(update parameters)}$</p>

<p>Where:</p>
<ul>
  <li>$\hat{y}$ is the model’s prediction given an input $x$.</li>
  <li>$W$ denotes the parameters.</li>
  <li>$\frac{\partial \mathcal{J}}{\partial W}$ is a gradient indicating the direction to push the value $W$ to decrease $\mathcal{J}$.</li>
  <li>$\alpha$ is the learning rate which you can tune to decide how much you want to adjust the value of $W$ per iteration.</li>
</ul>

<p>You can learn more about gradient-based optimization algorithms in the Deep Learning Specialization. This topic is covered in Course 1, Week 2 (Neural Network Basics) and Course 2, Week 2 (Optimization Algorithms).</p>

<p>Note that the cost $\mathcal{J}$ takes as input the entire training data set, so computing it at every iteration can be slow. It is common to minimize the average of the loss computed over a batch of examples; for instance, $\mathcal{J_{mini-batch}} = \frac{1}{m_b} \sum_{i=1}^{m_b} \mathcal{L}^{(i)}$. Reducing this function leads to a quicker parameter-update direction to minimize training error. $m_b$  is called the batch size. This is a key <span class="sidenote">hyperparameter</span> to tune.</p>

<h3 id="adjusting-gradient-descent-hyperparameters">Adjusting gradient descent hyperparameters</h3>

<p>To use gradient descent, you must choose values for hyperparameters such as learning rate and batch size. These values will influence the optimization, so it’s important to set them appropriately.</p>

<p>In the visualization below, try to discover the parameters used to generate a dataset. You are provided the ground truth from which the data was generated (the blue line) so that you can compare it to your trained model (the red line). Play with the starting point of initialization, learning rate, and batch size. Here are some questions to consider as you explore the visualization:</p>

<ul>
  <li>Why do the model parameters converge to values different than the ground-truth?</li>
  <li>What is the impact of the training set size?</li>
  <li>What is the impact of the learning rate on the optimization?</li>
  <li>Why does the cost landscape look like this?</li>
</ul>

<div class="visualization hide-backToTop" id="regression">
    <div class="visualization-column-4">
        <p>In this visualization, your goal is to recover the ground truth parameters used to generate a training set. You can fit a linear model $\hat{y} = wx + b$ on the training set using gradient descent. Press the button to generate a dataset of chosen size (<b>1</b>) and observe its impact on the cost landscape. Then, choose initial values of your model parameters by dragging the <span class="red">red dot</span> (<b>2</b>) before optimizing (<b>3</b>).</p>
    </div>
    <div class="visualization-column-1">
        <!-- <p>In this visualization, your goal is to recover the ground truth parameters used to generate a training set. You can fit a linear model <script>document.write(katex.renderToString('\\hat{y} = wx + b'))</script> on the training set using gradient descent. Press the button to generate a dataset of chosen size (<b>1</b>) and observe its impact on the cost landscape. Then, choose initial values of your model parameters by dragging the <span class="red">red dot</span> (<b>2</b>) before optimizing (<b>3</b>).</p> -->
        <h3>1. Generate a dataset</h3>
        <p>Select a training set size $m$.</p>
        <label class="radio-container">Small
            <input type="radio" value="20" name="regression_tsize" />
            <span class="checkmark"></span>
        </label>
        <label class="radio-container">Medium
            <input type="radio" value="300" name="regression_tsize" checked="" />
            <span class="checkmark"></span>
        </label>
        <label class="radio-container">Large
            <input type="radio" value="800" name="regression_tsize" />
            <span class="checkmark"></span>
        </label>
        <p>A training set of the chosen size will be sampled with noise from a line representing <span class="blue">ground truth</span>. This line is the target line for the <span class="red">model</span> defined by $\hat{y} = wx + b$.</p>
        <button class="button-transport" id="generate">
           Generate a new dataset.
        </button>
        <div id="regression_plot" style="margin-top:1em;border: 1px solid rgba(0,0,0,0.2);"></div>
    </div>
    <div class="visualization-column-2">
        <h3>2. Observe the cost landscape and initialize parameters.</h3>
        <p>The cost function is the L2 loss (defined as $\mathcal{L}(y, \hat{y}) = ||y - \hat{y}||_2^2$) averaged over the training set. The <span class="blue">blue dot</span> indicates the value of the cost function at the ground-truth slope and intercept. The <span class="red">red dot</span> indicates the value of the cost function at a chosen initialization of the slope and intercept. Drag and drop the red dot to change the initialization.</p>
        <div id="regression_landscape"></div>
    </div>
    <div class="visualization-column-1">
        <h3>3. Optimize the cost function</h3>
        <p>Now you can update the parameters iteratively to minimize the cost. Select a learning rate.</p>
        <label class="radio-container">Small
            <input type="radio" value="0.0001" name="regression_lrate" />
            <span class="checkmark"></span>
        </label>
        <label class="radio-container">Medium
            <input type="radio" value="0.01" name="regression_lrate" checked="" />
            <span class="checkmark"></span>
        </label>
        <label class="radio-container">Large
            <input type="radio" value="0.1" name="regression_lrate" />
            <span class="checkmark"></span>
        </label>
        <p>Select a batch size.</p>
        <label class="radio-container">$m_b = 1$
            <input type="radio" value="1" name="regression_bsize" checked="" />
            <span class="checkmark"></span>
        </label>
        <label class="radio-container">$m_b = 24$
            <input type="radio" value="24" name="regression_bsize" />
            <span class="checkmark"></span>
        </label>
        <label class="radio-container">$m_b = m$
            <input type="radio" value="300" name="regression_bsize" />
            <span class="checkmark"></span>
        </label>
        <p>Train the <span class="red">model</span>.</p>
        <button class="button-transport" id="regression_reset" title="reset">
            <img src="../assets/images/layout/reset.png" />
        </button>
        <button class="button-transport" id="regression_train" title="start">
            <img src="../assets/images/layout/play.png" />
        </button>
        <button class="button-transport hidden" id="regression_stop" title="stop">
            <img src="../assets/images/layout/pause.png" />
        </button>
        <div id="regression_loss"></div>
    </div>
</div>

<p>Here are some takeaways from the visualization:</p>
<ul>
  <li>Even if you choose the best possible hyperparameters, the trained model will not exactly match the provided ground truth (blue line) because the dataset is just a <span class="sidenote">proxy</span> for the ground-truth distribution.</li>
  <li>The larger the training set size, the closer your trained model parameters will be to the parameters used to generate the data.</li>
  <li>If your learning rate is too large, your algorithm won’t converge. If it is too small, your algorithm will converge slowly.</li>
  <li>If the initial point (the red dot) is close to the ground truth and the hyperparameters (learning rate and batch size) are tuned properly, your algorithm will converge quickly.</li>
</ul>

<p>As you can see, each hyperparameter has a different impact on the convergence of your algorithm. Let’s dig deeper into each hyperparameter.</p>

<!-- Kian, please add, as a series of bullets, a taleaway statement for initialization, learning rate, batch size, and iterative update. -->

<h3 id="initialization">Initialization</h3>

<p>A good initialization can accelerate optimization and enable it to converge to the minimum or, if there are several minima, the best one. To learn more about initialization, read our AI Note,  <a href="http://www.deeplearning.ai/ai-notes/initialization/"> <i>Initializing Neural Networks</i></a>.</p>

<h3 id="learning-rate">Learning rate</h3>

<p>The learning rate influences the optimization’s convergence. It also counterbalances the influence of the cost function’s curvature. According to the gradient descent formula above, the direction and magnitude of the parameter update is given by the learning rate multiplied by the slope of the cost function at a certain point $W$. Specifically: $\alpha \frac{\partial \mathcal{J}}{\partial W}$.</p>

<ul>
  <li>If the learning rate is too small, updates are small and optimization is slow, especially if the cost curvature is low. Also, you’re likely to settle into an <span class="sidenote">poor local minimum</span> or plateau.</li>
  <li>If the learning rate is too large, updates will be large and the optimization is likely to diverge, especially if the cost function’s curvature is high.</li>
  <li>If the learning rate is chosen well, updates are appropriate and the optimization should converge to a good set of parameters.</li>
</ul>

<p>Play with the visualization below to understand how learning rate and cost curvature influence an algorithm’s convergence.</p>

<div class="visualization hide-backToTop">
  <div class="visualization-column-1">
    <p>In this visualization, you are trying to find the parameter corresponding to the minimum of a cost function (<font color="blue">blue parabola</font>) using gradient descent. At a given point (<font color="blue">blue dot</font>), the cost function is approximated by its slope (<font color="orange">orange line</font>). You can tune the cost curvature and the learning rate, which together determine the direction and value of each parameter update and the approximation error (<font color="red">red line</font>).</p>
  </div>
  <div class="visualization-column-2">
    <svg id="loss" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 565 403">
        <rect id="frame" width="565" height="403" fill="none" />
        <g id="loss_graph" data-name="loss graph">
          <g id="axes">
            <line id="bottomLine" x1="61.48" y1="364.65" x2="523.48" y2="364.65" fill="none" stroke="#aaa" stroke-miterlimit="10" stroke-width="3" />
            <line id="vert" x1="61.48" y1="364.65" x2="61.48" y2="17.55" fill="none" stroke="#aaa" stroke-miterlimit="10" stroke-width="3" />
            <polygon id="left_arr" data-name="left arr" points="521.68 359.15 521.68 369.35 532.08 364.65 521.68 359.15" fill="#aaa" />
            <polygon id="up_arr" data-name="up arr" points="56.38 19.05 66.68 19.05 61.88 8.65 56.38 19.05" fill="#aaa" />
          </g>
          <line id="errorLine" x1="3" y1="8.65" x2="3" y2="8.65" fill="none" stroke="#ff1e00" stroke-miterlimit="10" stroke-width="3" />
          <path id="flat_curve" data-name="flat curve" d="M93.22,59.88S188.5,299.22,311.5,299.22,529.85,59.88,529.85,59.88" fill="none" stroke="#2665ba" stroke-linecap="round" stroke-miterlimit="10" stroke-width="3" />
          <path id="steep_curve" data-name="steep curve" d="M151,59.88s70.1,239.34,160.49,239.34S472.12,59.88,472.12,59.88" fill="none" stroke="#2665ba" stroke-linecap="round" stroke-miterlimit="10" stroke-width="3" />
          <line id="deriv" x1="523.48" y1="299.22" x2="99.59" y2="299.22" fill="none" stroke="red" stroke-miterlimit="10" stroke-width="3" />
          <line id="ph_deriv" data-name="ph deriv" x1="523.48" y1="299.22" x2="99.59" y2="299.22" fill="none" stroke="#ffa600" stroke-linecap="round" stroke-miterlimit="10" stroke-width="3" />
          <line id="learnLine" x1="3" y1="8.65" x2="3" y2="8.65" fill="none" stroke="#ffc900" stroke-linecap="round" stroke-miterlimit="10" stroke-width="4" />
          <circle id="cloneDot" cx="311.54" cy="299.22" r="6.66" fill="#ffdc58" />
          <circle id="phDot" cx="311.54" cy="299.22" r="6.66" fill="none" />
          <circle id="centerDot" cx="311.54" cy="299.22" r="6.66" fill="#5ea0fa" />
          <text transform="translate(10.35 19.05)" font-size="15" fill="#878787" font-family="Assistant" style="isolation: isolate">Cost</text>
          <text transform="translate(483.95 394.12)" font-size="15" fill="#878787" font-family="Assistant" style="isolation: isolate">Parameters</text>
        </g>
    </svg>
  </div>
  <div class="visualization-column-1">
    <p id="iter_text">Iteration: <span id="curvature_ittr">0</span></p>
    <p>Cost function curvature:</p>
    <label id="lo_toggle" class="radio-container">Low
        <input type="radio" value="20" name="curvature_crate" checked="" />
        <span class="checkmark"></span>
    </label>
    <label id="hi_toggle" class="radio-container">High
        <input type="radio" value="1000" name="curvature_crate" />
        <span class="checkmark"></span>
    </label>
    <p>Learning rate:</p>
    <label id="sm_toggle" class="radio-container">Small
        <input type="radio" value="800" name="curvature_lrate" />
        <span class="checkmark"></span>
    </label>
    <label id="big_toggle" class="radio-container">Large
        <input type="radio" value="800" name="curvature_lrate" checked="" />
        <span class="checkmark"></span>
    </label>
    <div>
    <button class="button-transport" id="replay" title="reset">
        <img src="../assets/images/layout/reset.png" /> Reset
    </button>
    <br />
    <img src="../assets/images/article/optimization/approx_error.png" style="width:50%" />
    </div>
  </div>
</div>

<p>The visualization illustrates that:</p>
<ul>
  <li>What makes a good learning rate depends on the curvature of the cost function.</li>
  <li>Gradient descent makes a linear approximation of the cost function at a given point. Then it moves downhill along the approximation of the cost function.</li>
  <li>If the cost is highly curved, the larger the learning rate (step size), the more likely is the algorithm to overshoot.</li>
  <li>Taking small steps reduces reduces this problem, but also slows down learning.<sup class="footnote"></sup></li>
</ul>

<p>It is common to start with a large learning rate — say, between 0.1 and 1 — and decay it during training. Choosing the right decay (how often? by how much?) is non-trivial. An excessively aggressive decay schedule slows progress toward the optimum, while a slow-paced decay schedule leads to chaotic updates with small improvements.</p>

<p>In fact, finding the “best decay schedule” is non trivial. However, adaptive learning-rate algorithms such as Momentum Adam and RMSprop help adjust the learning rate during the optimization process. We’ll explain those algorithms below.</p>

<h3 id="batch-size">Batch size</h3>

<p>Batch size is the number of data points used to train a model in each iteration. Typical small batches are 32, 64, 128, 256, 512, while large batches can be thousands of examples.</p>

<p>Choosing the right batch size is important to ensure convergence of the cost function and parameter values, and to the <span class="sidenote">generalization</span> of your model. Some research<sup class="footnote"></sup> has considered how to make the choice, but there is no consensus. In practice, you can use a <span class="sidenote">hyperparameter search</span>.</p>

<p>Research into batch size has revealed the following principles:</p>

<ul>
  <li>Batch size determines the frequency of updates. The smaller the batches, the more, and the quicker, the updates.</li>
  <li>The larger the batch size, the more accurate the gradient of the cost will be with respect to the parameters. That is, the direction of the update is most likely going down the local slope of the cost landscape.</li>
  <li>Having larger batch sizes, but not so large that they no longer fit in GPU memory, tends to improve parallelization efficiency and can accelerate training.</li>
  <li>Some authors (Keskar et al., 2016) have also suggested that large batch sizes can hurt the model’s ability to generalize, perhaps by causing the algorithm to find poorer local optima/plateau.</li>
</ul>

<p>In choosing batch size, there’s a balance to be struck depending on the available computational hardware and the task you’re trying to achieve.</p>

<h3 id="iterative-update">Iterative update</h3>

<p>Now that you have a starting point, a learning rate, and a batch size, it’s time to update the parameters iteratively to move toward the cost function’s minimum.</p>

<p>The optimization algorithm is also a core choice. You can play with various optimizers in the visualization below. That will help you build an intuitive sense of the pros and cons of each.</p>

<p>In the visualization below, your goal is to play with hyperparameters to find parameter values that minimize a cost function. You can choose the cost function and starting point of the optimization. Although there’s no explicit model, you can assume that finding the minimum of the cost function is equivalent to finding the best model for your task. For the sake of simplicity, the model only has two parameters and the batch size is always 1.</p>

<div class="visualization hide-backToTop" id="landscape">
    <div class="visualization-column-2">
        <p>In this visualization, you can compare optimizers applied to different cost functions and initialization. For a given cost landscape (<b>1</b>) and initialization (<b>2</b>), you can choose optimizers, their learning rate and decay (<b>3</b>). Then, press the play button to see the optimization process (<b>4</b>). There's no explicit model, but you can assume that finding the cost function's minimum is equivalent to finding the best model for your task.</p>

        <h3>1. Choose a cost landscape</h3>
        <p>Select an <a href="https://en.wikipedia.org/wiki/Test_functions_for_optimization">artificial landscape</a> $\mathcal{J}(w_1,w_2)$.</p>
        <div class="lossFunctions">
            <label>
              <input type="radio" name="loss" value="himmelblaus" checked="" />
              <img src="../assets/images/article/optimization/loss/himmelblaus.png" />
            </label>
            <label>
              <input type="radio" name="loss" value="styblinskiTang" />
              <img src="../assets/images/article/optimization/loss/styblinskiTang.png" />
            </label>
            <label>
              <input type="radio" name="loss" value="rosenbrock" />
              <img src="../assets/images/article/optimization/loss/rosenbrock.png" />
            </label>
            <label>
              <input type="radio" name="loss" value="goldsteinPrice" />
              <img src="../assets/images/article/optimization/loss/goldsteinPrice.png" />
            </label>
        </div>
        <h3>2. Choose initial parameters</h3>
        <p>On the <font color="blue">cost landscape graph</font>, drag the <font color="red">red dot</font> to choose initial parameter values and thus the initial value of the cost.</p>

        <h3>3. Choose an optimizer</h3>
        <p>Select the optimizer(s) and hyperparameters.</p>

        <table id="optimizer-table">
          <tr>
            <th>Optimizer</th>
            <th>Learning Rate</th>
            <th>Learning Rate Decay</th>
          </tr>
          <tr>
            <td>
                <div class="checkbox">
                    <input type="checkbox" name="opt" value="gd" checked="" />
                    <label>Gradient Descent</label>
                </div>

            </td>
            <td><input class="gd" type="number" name="lrate" value="0.001" min="0" max="1" step="0.0001" /></td>
            <td><input class="gd" type="number" name="ldecay" value="0" min="0" max="1" step="0.01" /></td>
          </tr>
          <tr>
            <td><input type="checkbox" name="opt" value="momentum" checked="" /> Momentum</td>
            <td><input class="momentum" type="number" name="lrate" value="0.001" min="0" max="1" step="0.0001" /></td>
            <td><input class="momentum" type="number" name="ldecay" value="0" min="0" max="1" step="0.01" /></td>
          </tr>
          <tr>
            <td><input type="checkbox" name="opt" value="rmsprop" checked="" /> RMSprop</td>
            <td><input class="rmsprop" type="number" name="lrate" value="0.001" min="0" max="1" step="0.0001" /></td>
            <td><input class="rmsprop" type="number" name="ldecay" value="0" min="0" max="1" step="0.01" /></td>
          </tr>
          <tr>
            <td><input type="checkbox" name="opt" value="adam" checked="" /> Adam</td>
            <td><input class="adam" type="number" name="lrate" value="0.001" min="0" max="1" step="0.0001" /></td>
            <td><input class="adam" type="number" name="ldecay" value="0" min="0" max="1" step="0.01" /></td>
          </tr>
        </table>
        <h3>4. Optimize the cost function</h3>
        <button class="button-transport" id="reset" title="reset">
            <img src="../assets/images/layout/reset.png" />
        </button>
        <button class="button-transport" id="train" title="start">
            <img src="../assets/images/layout/play.png" />
        </button>
        <button class="button-transport hidden" id="stop" title="stop">
            <img src="../assets/images/layout/pause.png" />
        </button>
    </div>
    <div class="visualization-column-2">
        <p> This 2D plot describes the cost function's value for different values of the two parameters $(w_1,w_2)$. The lighter the color, the smaller the cost value.</p>
        <div id="landscape_contour"></div>
        <p>The graph below shows how the value of the cost changes through successive epochs for each optimizer.</p>
        <div id="landscape_loss"></div>
    </div>
</div>

<h3 id="choice-of-optimizer">Choice of optimizer</h3>

<p>The choice of optimizer influences both the speed of convergence and whether it occurs. Several alternatives to the classic gradient descent algorithms have been developed in the past few years and are listed in the table below. (Notation: $dW = \frac{\partial \mathcal{J}}{\partial W}$)</p>

<table class="full-width hide-backToTop">
  <tr>
    <th>Optimizer</th>
    <th>Update rule</th> 
    <th>Attribute</th>
  </tr>
  <tr>
    <td>(Stochastic) Gradient Descent</td>
    <td>
        $W = W - \alpha dW$
    </td>
    <td>
        <ul>
            <li>Gradient descent can use parallelization efficiently, but is very slow when the data set is larger the GPU's memory can handle. The parallelization wouldn't be optimal.</li>
            <li>Stochastic gradient descent usually converges faster than gradient descent on large datasets, because updates are more frequent. Plus, the stochastic approximation of the gradient is usually precise without using the whole dataset because the data is often redundant.</li>
            <li>Of the optimizers profiled here, stochastic gradient descent uses the least memory for a given batch size.</li>
        </ul>
    </td>
  </tr>
  <tr>
    <td>Momentum</td>
    <td>
        $$
        \begin{aligned}
        V_{dW} &amp;= \beta V_{dW} + ( 1 - \beta ) dW\\
        W &amp;= W - \alpha V_{dW}
        \end{aligned}
        $$
     </td>
    <td>    
        <ul>
            <li>Momentum usually speeds up the learning with a very minor implementation change.
                <li>Momentum uses more memory for a given batch size than stochastic gradient descent but less than RMSprop and Adam.</li></li>
        </ul>
    </td>
  </tr>
  <tr>
    <td>RMSprop</td>
    <td>
        $$
        \begin{aligned}
        S_{dW} &amp;= \beta S_{dW} + ( 1 - \beta ) dW^2\\
        W &amp;= W - \alpha \frac{dW}{\sqrt{S_{dW}} + \varepsilon}
        \end{aligned}
        $$
    </td>
    <td>
        <ul>
            <li>RMSprop’s adaptive learning rate usually prevents the learning rate decay from diminishing too slowly or too fast.</li>
            <li>RMSprop maintains per-parameter learning rates.</li>
            <!--<li>RMSprop usually works well in <span class="sidenote">online</span> and <span class="sidenote">non-stationary settings</span>.</li>-->
            <li>RMSprop uses more memory for a given batch size than stochastic gradient descent and Momentum, but less than Adam.</li>
        </ul>
    </td>
  </tr>
  <tr>
    <td><a href="https://arxiv.org/pdf/1412.6980.pdf">Adam</a></td>
    <td>
        $$
        \begin{aligned}
        V_{dW} &amp;= \beta_1 V_{dW} + ( 1 - \beta_1 ) dW\\
        S_{dW} &amp;= \beta_2 S_{dW} + ( 1 - \beta_2 ) dW^2\\
        Vcorr_{dW} &amp;= \frac{V_{dW}}{(1 - \beta_1)^t}\\
        Scorr_{dW} &amp;= \frac{S_{dW}}{(1 - \beta_2)^t}\\
        W &amp;= W - \alpha \frac{dW}{\sqrt{S_{dW}} + \varepsilon}
        \end{aligned}
        $$
     </td>
    <td>
        <ul>
            <li>The hyperparameters of Adam (learning rate, exponential decay rates for the moment estimates, etc.) are usually set to predefined values (given in the paper), and do not need to be tuned.</li>
            <li>Adam performs a form of learning rate annealing with adaptive step-sizes.</li>
            <li>Of the optimizers profiled here, Adam uses the most memory for a given batch size.</li>
            <li>Adam is often the default optimizer in machine learning.</li>
        </ul>
    </td>
  </tr>
</table>

<p>Adaptive optimization methods such as Adam or RMSprop perform well in the initial portion of training, but they have been found to generalize poorly at later stages compared to Stochastic Gradient Descent.</p>

<p>You can find more information about these optimizers in the Deep Learning Specialization Course 2, Week 2 (Optimization Algorithms) on Coursera.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Exploring optimization methods and hyperparameter values can help you build intuition for optimizing networks for your own tasks. During hyperparameter search, it’s important to understand intuitively the optimization’s sensitivity to learning rate, batch size, optimizer, and so on. That intuitive understanding, combined with the right method (random search or Bayesian optimization), will help you find the right model.</p>

                
                    <div class="sidenote-body">
                        <p class="caption">By definition, this function L has a low value when the model performs well on the task.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">Do you know the mathematical formula that allows a neural network to detect cats in images? Probably not. But using data you can find a function that performs this task. It turns out that a convolutional architecture with the right parameters defines a function that can perform this task well.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">Close-form methods attempt to solve a problem in a finite sequence of algebraic operations. For instance, you can find the point achieving the minimum of $f(x) = x^2 + 1$ by solving $f'(x) = 0$ which leads to $2x = 0 \implies x=0$.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">In addition to learning parameters for a model, you also need reasonable choices of hyperperameters that affect training, such as batch size and learning rate.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">In theory, if you sampled infinitely many data points from the distribution and fit a linear model, you could recover the ground truth parameters.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">We use the term poor local minimum because, in optimizing a machine learning model, the optimization is often non-convex and unlikely to converge to the global minimum.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">Generalization refers to your model's ability to perform well on unseen data. In order to evaluate the generalization of your model, you can train your model on a training set and evaluate it on a hold-out test set.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">For more information on hyperparameter tuning, see the Deep Learning Specialization Course 2, Week 3 (Hyperparameter Tuning, Batch Normalization and Programming Frameworks).</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">This term essentially describes inflection points (where the concavity of the landscape changes) for which the gradient is zero in some, but not all, directions.</p>
                    </div>
                
                    <div class="sidenote-body">
                        <p class="caption">Gradient descent makes a linear approximation of the cost function in a given point. It then moves downhill along the approximation of the cost function.</p>
                    </div>
                
        </section>

    </div>




    <div class="foot-note">

            <div class="foot-note-header">
                <h4 class="reference">Authors</h4>
            </div>
            <div class="foot-note-content">
                <ol class="reference ">
                    
                    <li><a href="https://twitter.com/kiankatan">Kian Katanforoosh</a> - Content and structure.</li>
                    
                    <li><a href="http://daniel-kunin.com">Daniel Kunin</a> - Visualizations (created using <a href="https://d3js.org/">D3.js</a> and <a href="https://js.tensorflow.org/">TensorFlow.js</a>).</li>
                    
                    <li><a href="https://majiaju.io/">Jiaju Ma</a> - Static and interactive graphics.</li>
                    
                </ol>
            </div>

            
            <div class="foot-note-header">
                <h4 class="reference">Acknowledgments</h4>
            </div>
            <div class="foot-note-content">
                <ol class="reference">
                    
                    <li>The template for the article was designed by <a href="https://www.jingru-guo.com/">Jingru Guo</a> and inspired by <a href="https://distill.pub/">Distill</a>.</li>
                    
                    <li>The loss landscape visualization adapted code from Mike Bostock's <a href="https://bl.ocks.org/mbostock/f48ff9c1af4d637c9a518727f5fdfef5">visualization</a> of the Goldstein-Price function.</li>
                    
                    <li>The banner visualization adapted code from deeplearn.js's implementation of a <a href="https://en.wikipedia.org/wiki/Compositional_pattern-producing_network">CPPN</a>.</li>
                    
                </ol>
            </div>
            

            
            <div class="foot-note-header">
                <h4 class="reference">Footnotes</h4>
            </div>
            <div class="foot-note-content">
                <ol class="reference" id="fn">
                   
                    <li class="footnote-body"><span>Chapter 4, <i>Deep Learning</i>, Goodfellow et al. (MIT Press)</span></li>
                    
                    <li class="footnote-body"><span>Check out these papers&#58; <ul><li><a href="https://arxiv.org/pdf/1711.00489.pdf"><i>Don't decay the learning rate, increase the batch size</i></a></li> <li><a href="https://papers.nips.cc/paper/6770-train-longer-generalize-better-closing-the-generalization-gap-in-large-batch-training-of-neural-networks.pdf"><i>Train longer generalize better</i></a></li> <li><a href="https://arxiv.org/pdf/1706.02677.pdf"><i>Accurate, large minibatch SGD</i></a></li></ul></span></li>
                    
                </ol>
            </div>
            


            <div class="foot-note-header">
                <h4 class="reference">Reference</h4>
            </div>
            <div class="foot-note-content">
                <p class="reference">To reference this article in an academic context, please cite this work as:</p>
                <p class="citation">Katanforoosh, Kunin et al., "Optimizing neural networks", deeplearning.ai, 2019.</p>
               
            </div>

</div>

    

<div class="footer-generic hide-backToTop">

    <div class="container">
        <p class="footer-note">
            Contact us at hello@deeplearning.ai</br>
            © Deeplearning.ai 2018</br>
            <a href="https://www.deeplearning.ai/privacy/">PRIVACY POLICY</a> <a href="https://www.deeplearning.ai/terms-of-use/">TERMS OF USE</a>
        </p>


        <div class="social">
                <a href="https://www.facebook.com/deeplearningHQ/"><i class="fab fa-facebook fontAwesomeIcon" ></i></a>
                <a href="https://twitter.com/deeplearningai_"><i class="fab fa-twitter-square fontAwesomeIcon"></i></a>
                <a href="https://www.linkedin.com/company/deeplearningai/"><i class="fab fa-linkedin fontAwesomeIcon"></i></a>
        </div>
    </div>
</div>
   
<div class="backToTop">
    <p>↑ Back to top</p>
</div>


    
      
      <link rel="stylesheet" href="/assets/css/article/optimization/landscape.css" >
      
      <link rel="stylesheet" href="/assets/css/article/optimization/regression.css" >
      
    

    
      
      <script src="/assets/js/article/optimization/curvature.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/regression/loss.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/regression/optimizer.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/regression/line.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/regression/viz.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/landscape/point.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/landscape/loss.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/landscape/optimizer.js" type="text/javascript"></script>
      
      <script src="/assets/js/article/optimization/landscape/viz.js" type="text/javascript"></script>
      
       
  

  </body>


  
</html>